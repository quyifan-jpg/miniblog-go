package main

import (
	"context"
	"fmt"
	"log"
	"os"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/cloudwego/eino/schema"
)

/*
ç¤ºä¾‹ 4ï¼šChain ç¼–æ’
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Chain å°†å¤šä¸ªæ­¥éª¤ä¸²è”èµ·æ¥
*/

func main() {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		log.Fatal("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
	}

	ctx := context.Background()

	// åˆ›å»º ChatModel
	chatModel, err := openai.NewChatModel(ctx, &openai.ChatModelConfig{
		Model:  "gpt-3.5-turbo",
		APIKey: apiKey,
	})
	if err != nil {
		log.Fatalf("åˆ›å»º ChatModel å¤±è´¥: %v", err)
	}

	fmt.Println("ğŸ”— Chain ç¼–æ’ç¤ºä¾‹")
	fmt.Println()

	// åˆ›å»ºä¸€ä¸ªç®€å•çš„ Chain
	// 
	// Chain æ•°æ®æµè¯´æ˜ï¼š
	// 1. åˆå§‹è¾“å…¥: runnable.Invoke(ctx, "ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ") 
	//    â†“
	// 2. preprocessor çš„ input = "ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ" (åŸå§‹ç”¨æˆ·è¾“å…¥)
	//    â†“ è¾“å‡º: "ç”¨æˆ·é—®é¢˜: ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ"
	// 3. llmStep çš„ input = "ç”¨æˆ·é—®é¢˜: ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ" (preprocessor çš„è¾“å‡º)
	//    â†“ è¾“å‡º: LLM ç”Ÿæˆçš„å›å¤å†…å®¹
	// 4. postprocessor çš„ input = LLM çš„å›å¤å†…å®¹ (llmStep çš„è¾“å‡º)
	//    â†“ è¾“å‡º: "ã€AI å›å¤ã€‘\n{LLMå›å¤å†…å®¹}"
	
	// æ­¥éª¤1: é¢„å¤„ç†è¾“å…¥
	// input: åŸå§‹ç”¨æˆ·è¾“å…¥ (ä¾‹å¦‚: "ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ")
	preprocessor := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		fmt.Printf("ğŸ“ æ­¥éª¤1 - é¢„å¤„ç†: æ¸…ç†è¾“å…¥...\n")
		fmt.Printf("   [è¾“å…¥] input = %q\n", input)
		cleaned := fmt.Sprintf("ç”¨æˆ·é—®é¢˜: %s", input)
		fmt.Printf("   [è¾“å‡º] cleaned = %q\n", cleaned)
		return cleaned, nil
	})

	// æ­¥éª¤2: è°ƒç”¨ LLM
	// input: preprocessor çš„è¾“å‡º (ä¾‹å¦‚: "ç”¨æˆ·é—®é¢˜: ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ")
	llmStep := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		fmt.Printf("ğŸ¤– æ­¥éª¤2 - è°ƒç”¨ LLM: ç”Ÿæˆå›ç­”...\n")
		fmt.Printf("   [è¾“å…¥] input = %q\n", input)
	
		// 1. åº”ç”¨ Prompt æ¨¡æ¿
		promptTemplate := "è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š%s"
		finalPrompt := fmt.Sprintf(promptTemplate, input)
		fmt.Printf("   [å¤„ç†] finalPrompt = %q\n", finalPrompt)
	
		// 2. å®é™…è°ƒç”¨ LLM
		messages := []*schema.Message{
			{Role: schema.User, Content: finalPrompt},
		}
		
		response, err := chatModel.Generate(ctx, messages) 
		if err != nil {
			return "", err
		}
	
		fmt.Printf("   [è¾“å‡º] response.Content = %q\n", response.Content)
		return response.Content, nil
	})

	// æ­¥éª¤3: åå¤„ç†è¾“å‡º
	// input: llmStep çš„è¾“å‡º (ä¾‹å¦‚: LLM ç”Ÿæˆçš„å›å¤å†…å®¹)
	postprocessor := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		fmt.Printf("âœ¨ æ­¥éª¤3 - åå¤„ç†: æ ¼å¼åŒ–è¾“å‡º...\n")
		fmt.Printf("   [è¾“å…¥] input = %q\n", input)
		formatted := fmt.Sprintf("ã€AI å›å¤ã€‘\n%s", input)
		fmt.Printf("   [è¾“å‡º] formatted = %q\n", formatted)
		return formatted, nil
	})

	// åˆ›å»º Chain å¹¶æ·»åŠ æ­¥éª¤
	chain := compose.NewChain[string, string]()
	chain.AppendLambda(preprocessor)
	chain.AppendLambda(llmStep)
	chain.AppendLambda(postprocessor)

	// ç¼–è¯‘ Chain
	fmt.Println("â–¶ï¸  å¼€å§‹æ‰§è¡Œ Chain...")
	fmt.Println()

	runnable, err := chain.Compile(ctx)
	if err != nil {
		log.Fatalf("Chain ç¼–è¯‘å¤±è´¥: %v", err)
	}

	// æ‰§è¡Œ Chain
	result, err := runnable.Invoke(ctx, "ä»€ä¹ˆæ˜¯ Eino æ¡†æ¶ï¼Ÿ")
	if err != nil {
		log.Fatalf("Chain æ‰§è¡Œå¤±è´¥: %v", err)
	}

	fmt.Println()
	fmt.Println("âœ… æœ€ç»ˆç»“æœ:")
	fmt.Println(result)
}

/*
è¿è¡Œæ–¹å¼:
export OPENAI_API_KEY=your_api_key
go run 04_chain.go

é¢„æœŸè¾“å‡º:
ğŸ”— Chain ç¼–æ’ç¤ºä¾‹

â–¶ï¸  å¼€å§‹æ‰§è¡Œ Chain...

ğŸ“ æ­¥éª¤1 - é¢„å¤„ç†: æ¸…ç†è¾“å…¥...
ğŸ¤– æ­¥éª¤2 - è°ƒç”¨ LLM: ç”Ÿæˆå›ç­”...
âœ¨ æ­¥éª¤3 - åå¤„ç†: æ ¼å¼åŒ–è¾“å‡º...

âœ… æœ€ç»ˆç»“æœ:
ã€AI å›å¤ã€‘
è¿™æ˜¯ AI ç”Ÿæˆçš„å›ç­”
*/

